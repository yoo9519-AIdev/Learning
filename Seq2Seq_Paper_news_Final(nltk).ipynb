{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_Paper_news_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1vzmLpeU80h9z0E17CDPnSO433OTRs62o",
      "authorship_tag": "ABX9TyM7l08z4ujMiZFy8/7zCAI9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoo9519-AIdev/Learning/blob/master/Seq2Seq_Paper_news_Final(nltk).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbhFyvhLxkQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nslRFSGxsVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "444a1253-d8cc-4316-b64a-8de437fc80b5"
      },
      "source": [
        "text = pd.read_excel('/content/drive/My Drive/AI NLP 알고리즘 포트폴리오/Seq2Seq/3_문어체_뉴스(1)_200226.xlsx')\n",
        "text"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>날짜</th>\n",
              "      <th>자동분류1</th>\n",
              "      <th>자동분류2</th>\n",
              "      <th>자동분류3</th>\n",
              "      <th>URL</th>\n",
              "      <th>언론사</th>\n",
              "      <th>원문</th>\n",
              "      <th>번역문</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20961563</td>\n",
              "      <td>2018-10-01 00:00:00</td>\n",
              "      <td>경제,국제경제</td>\n",
              "      <td>IT_과학,IT_과학일반</td>\n",
              "      <td>문화,문화일반</td>\n",
              "      <td>http://www.sedaily.com/NewsView/1S5QRSR5T2</td>\n",
              "      <td>서울경제</td>\n",
              "      <td>스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.</td>\n",
              "      <td>Skinner's reward is mostly eye-watering.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20930897</td>\n",
              "      <td>2018-09-14 00:00:00</td>\n",
              "      <td>IT_과학,IT_과학일반</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www.sedaily.com/NewsView/1S4MSFM0IH</td>\n",
              "      <td>서울경제</td>\n",
              "      <td>심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.</td>\n",
              "      <td>Even some problems can be predicted.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20307875</td>\n",
              "      <td>2019-04-19 00:00:00</td>\n",
              "      <td>IT_과학,과학</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://news.kmib.co.kr/article/view.asp?arcid=...</td>\n",
              "      <td>국민일보</td>\n",
              "      <td>오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.</td>\n",
              "      <td>Only God will exactly know why.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20314977</td>\n",
              "      <td>2019-04-27 00:00:00</td>\n",
              "      <td>국제,중국</td>\n",
              "      <td>경제,국제경제</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://news.kmib.co.kr/article/view.asp?arcid=...</td>\n",
              "      <td>국민일보</td>\n",
              "      <td>중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.</td>\n",
              "      <td>Businesses should not overlook China's dispute.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20268904</td>\n",
              "      <td>2019-03-13 00:00:00</td>\n",
              "      <td>문화,방송_연예</td>\n",
              "      <td>사회,미디어</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://news.kmib.co.kr/article/view.asp?arcid=...</td>\n",
              "      <td>국민일보</td>\n",
              "      <td>박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.</td>\n",
              "      <td>Slow-beating songs often float over time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>2469942</td>\n",
              "      <td>20181022</td>\n",
              "      <td>사회,노동_복지</td>\n",
              "      <td>사회,사건_사고</td>\n",
              "      <td>사회,미디어</td>\n",
              "      <td>http://www.hani.co.kr/arti/opinion/because/866...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>당시에는 경찰의 금지통보로 청와대 근처 집회가 불가능하던 시절이라 과연 경찰이 막지...</td>\n",
              "      <td>At the time, it was a period when it was impos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>2462113</td>\n",
              "      <td>20181019</td>\n",
              "      <td>사회,사건_사고</td>\n",
              "      <td>정치,정치일반</td>\n",
              "      <td>사회,노동_복지</td>\n",
              "      <td>http://www.hani.co.kr/arti/society/society_gen...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>양승태 대법원과 박근혜 청와대의 대표적 재판거래 의혹 사건으로 꼽히는 전국교직원노동...</td>\n",
              "      <td>The testimony of a Blue House official at the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>2463985</td>\n",
              "      <td>20181019</td>\n",
              "      <td>경제,산업_기업</td>\n",
              "      <td>사회,사회일반</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www.hani.co.kr/arti/society/society_gen...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>윤석열 서울중앙지검장이 19일 국정감사에 출석해 ‘적폐수사 1호’로 꼽히는 한국항공...</td>\n",
              "      <td>Seoul Central District Prosecutor's Office Chi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200009</th>\n",
              "      <td>2463107</td>\n",
              "      <td>20181019</td>\n",
              "      <td>사회,사건_사고</td>\n",
              "      <td>국제,유럽_EU</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www.hani.co.kr/arti/society/society_gen...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>대법원에 재상고된 지 5년이 넘도록 재판이 지연되면서 양승태 대법원장 시절 대표적인...</td>\n",
              "      <td>The date of the ruling of the second appeal re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200010</th>\n",
              "      <td>2463530</td>\n",
              "      <td>20181019</td>\n",
              "      <td>사회,사건_사고</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www.hani.co.kr/arti/opinion/editorial/8...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>‘양승태 대법원'은 민사소송규칙까지 고쳐 외교부가 대법원에 의견서를 제출할 수 있게...</td>\n",
              "      <td>It was also revealed through documents from th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200011 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID  ...                                                번역문\n",
              "0       20961563  ...           Skinner's reward is mostly eye-watering.\n",
              "1       20930897  ...               Even some problems can be predicted.\n",
              "2       20307875  ...                    Only God will exactly know why.\n",
              "3       20314977  ...    Businesses should not overlook China's dispute.\n",
              "4       20268904  ...          Slow-beating songs often float over time.\n",
              "...          ...  ...                                                ...\n",
              "200006   2469942  ...  At the time, it was a period when it was impos...\n",
              "200007   2462113  ...  The testimony of a Blue House official at the ...\n",
              "200008   2463985  ...  Seoul Central District Prosecutor's Office Chi...\n",
              "200009   2463107  ...  The date of the ruling of the second appeal re...\n",
              "200010   2463530  ...  It was also revealed through documents from th...\n",
              "\n",
              "[200011 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGGADAdix9XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text[:70000]\n",
        "text = text[['원문', '번역문']]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH1kjU21yPzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ko = text['원문']\n",
        "eng = text['번역문']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmU7EmWL0Gnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eng = eng.apply(lambda x : '<sos> '+ x + ' <eos>')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwIhtj2SzH7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9ce0b37-b43d-4f76-9732-b2979a6ba346"
      },
      "source": [
        "eng[0] # eg = eng[i]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Skinner's reward is mostly eye-watering.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJxB0tnRy0Sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7985b7c7-403a-42f9-ac70-9a5d088610ba"
      },
      "source": [
        "ko[0] # k = ko[i]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hKal99eyWoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = [k.split() for k in ko] # 단어 단위로 encoder_input에 담는다.\n",
        "decoder_input = [['<sos>'] + eg.split() for eg in eng]\n",
        "decoder_target = [eg.split() + ['<eos>'] for eg in eng]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzDzAkBo26tf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "8b36aae8-3f5d-4a16-80f5-808c888261a8"
      },
      "source": [
        "encoder_input[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['스키너가', '말한', '보상은', '대부분', '눈으로', '볼', '수', '있는', '현물이다.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFqq7nR_2VpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "95238aee-94ca-463b-9f17-752371f05a60"
      },
      "source": [
        "decoder_input[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', \"Skinner's\", 'reward', 'is', 'mostly', 'eye-watering.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH8nfIUC4asY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "e5b80168-4ce6-4153-d394-21f1e5caf594"
      },
      "source": [
        "decoder_target[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Skinner's\", 'reward', 'is', 'mostly', 'eye-watering.', '<eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3u_FJQ1EDaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pd_decoder_input = pd.DataFrame(decoder_input)\n",
        "# pd_decoder_input = pd_decoder_input.apply(lambda x: '<sos> ' + x)\n",
        "# pd_decoder_input"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-AIeZaLhfcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "ac008a8e-6bca-4f40-e0d3-c0eca3a16a06"
      },
      "source": [
        "decoder_input[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<sos>', \"Skinner's\", 'reward', 'is', 'mostly', 'eye-watering.'],\n",
              " ['<sos>', 'Even', 'some', 'problems', 'can', 'be', 'predicted.'],\n",
              " ['<sos>', 'Only', 'God', 'will', 'exactly', 'know', 'why.'],\n",
              " ['<sos>', 'Businesses', 'should', 'not', 'overlook', \"China's\", 'dispute.'],\n",
              " ['<sos>', 'Slow-beating', 'songs', 'often', 'float', 'over', 'time.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNU8-HlChiId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "c1e55b85-96f1-4548-f462-8ce84dedd9c2"
      },
      "source": [
        "decoder_target[:5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"Skinner's\", 'reward', 'is', 'mostly', 'eye-watering.', '<eos>'],\n",
              " ['Even', 'some', 'problems', 'can', 'be', 'predicted.', '<eos>'],\n",
              " ['Only', 'God', 'will', 'exactly', 'know', 'why.', '<eos>'],\n",
              " ['Businesses', 'should', 'not', 'overlook', \"China's\", 'dispute.', '<eos>'],\n",
              " ['Slow-beating', 'songs', 'often', 'float', 'over', 'time.', '<eos>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am671v841rST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 케라스 토크나이저를 통해 단어집합을 생성하고, 텍스트 시퀀스를 정수 시퀀스로 변환하는 정수 인코딩 과정을 거친다.\n",
        "\n",
        "tokenizer_ko = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_ko.fit_on_texts(encoder_input)\n",
        "encoder_input_ = tokenizer_ko.texts_to_sequences(encoder_input)\n",
        "\n",
        "tokenizer_eng = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_eng.fit_on_texts(decoder_input)\n",
        "decoder_input_ = tokenizer_eng.texts_to_sequences(decoder_input)\n",
        "decoder_target_ = tokenizer_eng.texts_to_sequences(decoder_target)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZXB6YVgiTJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_ = pad_sequences(encoder_input_, padding=\"post\")\n",
        "decoder_input_ = pad_sequences(decoder_input_, padding=\"post\")\n",
        "decoder_target_ = pad_sequences(decoder_target_, padding=\"post\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz3pYZJ-pPrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "96e43c65-f6ab-4752-f10a-e3d0befbd62a"
      },
      "source": [
        "decoder_target_ = pad_sequences(decoder_target_, padding='post')\n",
        "decoder_target_.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjVNSlxpilAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "157d9081-7922-423d-80db-5869a0fa78f9"
      },
      "source": [
        "encoder_input_.shape, decoder_input_.shape, decoder_target_.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70000, 30), (70000, 28), (70000, 27))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y5iYPLZixjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "295967d0-4e31-4045-936c-305190016b5c"
      },
      "source": [
        "ko_vocab_size = len(tokenizer_ko.word_index) + 1\n",
        "eng_vocab_size = len(tokenizer_eng.word_index) + 1\n",
        "print(\"한국어 단어 집합의 크기 : {:d}, 영어 단어 집합의 크기 : {:d}\".format(ko_vocab_size, eng_vocab_size))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "한국어 단어 집합의 크기 : 236187, 영어 단어 집합의 크기 : 99007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfOPF-bujFjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ko_to_index = tokenizer_ko.word_index\n",
        "index_to_ko = tokenizer_ko.index_word # 훈련 후 결과 비교할 때 사용\n",
        "\n",
        "eng_to_index = tokenizer_eng.word_index # 훈련 후 예측 과정에서 사용\n",
        "index_to_eng = tokenizer_eng.index_word # 훈련 후 결과 비교할 때 사용"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlfWYuFH0gxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_to_index_ = eng_to_index\n",
        "eng_to_index_['<eos>'] = 22163"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZCChQjUjQ7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "366eb520-0539-42ab-8378-b64d031c569e"
      },
      "source": [
        "indices = np.arange(encoder_input_.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  345  8446 11919 ... 31648 10173 58926]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uVDua6gjU-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_ = encoder_input_[indices]\n",
        "decoder_input_ = decoder_input_[indices]\n",
        "decoder_target_ = decoder_target_[indices]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb_xVSH-japC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "12fd578d-6a63-4cf5-a803-d33d02bbc080"
      },
      "source": [
        "# 훈련 데이터 분리\n",
        "\n",
        "n_of_val = int(33000*0.1)\n",
        "print(n_of_val)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pSxCapxjgIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_train = encoder_input_[:-n_of_val]\n",
        "decoder_input_train = decoder_input_[:-n_of_val]\n",
        "decoder_target_train = decoder_target_[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input_[-n_of_val:]\n",
        "decoder_input_test = decoder_input_[-n_of_val:]\n",
        "decoder_target_test = decoder_target_[-n_of_val:]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c3x7M7YjlRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "fb47b17c-2c80-44bd-9180-86e575175c89"
      },
      "source": [
        "print(encoder_input_train.shape)\n",
        "print(decoder_input_train.shape)\n",
        "print(decoder_target_train.shape)\n",
        "print(encoder_input_test.shape)\n",
        "print(decoder_input_test.shape)\n",
        "print(decoder_target_test.shape)\n",
        "\n",
        "# 차원 25, 16, 16로 조정"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66700, 30)\n",
            "(66700, 28)\n",
            "(66700, 27)\n",
            "(3300, 30)\n",
            "(3300, 28)\n",
            "(3300, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6s2ewm0rXVO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "c62d78da-3d32-41b7-83d0-19a51d5f3b1a"
      },
      "source": [
        "a_zero = np.zeros((66700, 1))\n",
        "b_zero = np.zeros((3300, 1))\n",
        "\n",
        "decoder_target_train = np.append(decoder_target_train, a_zero, axis=1)\n",
        "decoder_target_test = np.append(decoder_target_test, b_zero, axis=1)\n",
        "\n",
        "print(encoder_input_train.shape)\n",
        "print(decoder_input_train.shape)\n",
        "print(decoder_target_train.shape)\n",
        "print(encoder_input_test.shape)\n",
        "print(decoder_input_test.shape)\n",
        "print(decoder_target_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66700, 30)\n",
            "(66700, 28)\n",
            "(66700, 28)\n",
            "(3300, 30)\n",
            "(3300, 28)\n",
            "(3300, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7RTNGVVsJrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a_zero = np.zeros((6700, 1))\n",
        "# b_zero = np.zeros((3300, 1))\n",
        "\n",
        "# np.append(decoder_target_train, a_zero, axis=1)\n",
        "# np.append(decoder_target_test, b_zero, axis=1)\n",
        "\n",
        "# print(decoder_target_train.shape)\n",
        "# print(decoder_target_test.shape)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxKhIQwvpZFP",
        "colab_type": "text"
      },
      "source": [
        "numpy 배열 확인 및 조정(연습)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNdnq_Fak_Nb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "dec736e2-5b77-4c78-ba3a-ebd37ad3a47a"
      },
      "source": [
        "decoder_input_test"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   2,   11,   80, ...,    0,    0,    0],\n",
              "       [   2, 5056,    6, ...,    0,    0,    0],\n",
              "       [   2,   57,  192, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   2,  751, 1561, ...,    0,    0,    0],\n",
              "       [   2,  675, 5620, ...,    0,    0,    0],\n",
              "       [   2,   11, 2574, ..., 3274, 3642,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G45lqL5dnt7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "1901ce65-a490-4009-d65b-6548355fafca"
      },
      "source": [
        "testnp = np.arange(1, 21)\n",
        "testnp"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFoMov06n8IU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "a43bbda6-be03-4f26-e0ce-65035278d356"
      },
      "source": [
        "testnp2 = testnp.reshape(5, 4)\n",
        "testnp2.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLLjgElmpBL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "5d370cd5-e19e-4734-c080-3af2b23204f4"
      },
      "source": [
        "testnp2.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW1AchyBoMYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "33bdc7e4-f52c-4629-9e81-e1a75774fd54"
      },
      "source": [
        "a = np.zeros((5, 1))\n",
        "np.append(testnp2, a, axis=1)\n",
        "\n",
        "# 이런식으로 decoder_target_test / train을 수동으로 zeros패딩 시켜주자."
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  2.,  3.,  4.,  0.],\n",
              "       [ 5.,  6.,  7.,  8.,  0.],\n",
              "       [ 9., 10., 11., 12.,  0.],\n",
              "       [13., 14., 15., 16.,  0.],\n",
              "       [17., 18., 19., 20.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhdLOknRjn4G",
        "colab_type": "text"
      },
      "source": [
        "## Seq2Seq 기계 번역기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRLkreDJjs1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Y-RwAdjyGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 50"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9kiTI-fjzyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더\n",
        "\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(ko_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhmBI_zokAcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더\n",
        "\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(eng_vocab_size, latent_dim) # 임베딩 층\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "\n",
        "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "decoder_dense = Dense(eng_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyubdfWQkMFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYrU-Sy_kO-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxEoP8UJkTK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "d8b616af-d0be-4777-a622-ac382457e5ca"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 50)     11809350    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 50)     4950350     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking (Masking)               (None, None, 50)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "masking_1 (Masking)             (None, None, 50)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50), (None,  20200       masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       masking_1[0][0]                  \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 99007)  5049357     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 21,849,457\n",
            "Trainable params: 21,849,457\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d36-vEqnkU18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "f0e830ff-90f6-4d62-8e4d-eaf56835b5e5"
      },
      "source": [
        "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test), batch_size = 128, epochs = 10)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "522/522 [==============================] - 279s 534ms/step - loss: 6.4680 - acc: 0.2423 - val_loss: 5.7699 - val_acc: 0.3047\n",
            "Epoch 2/10\n",
            "522/522 [==============================] - 275s 528ms/step - loss: 5.6221 - acc: 0.3183 - val_loss: 5.5184 - val_acc: 0.3286\n",
            "Epoch 3/10\n",
            "522/522 [==============================] - 275s 527ms/step - loss: 5.3583 - acc: 0.3419 - val_loss: 5.3085 - val_acc: 0.3489\n",
            "Epoch 4/10\n",
            "522/522 [==============================] - 275s 527ms/step - loss: 5.1686 - acc: 0.3570 - val_loss: 5.1718 - val_acc: 0.3605\n",
            "Epoch 5/10\n",
            "522/522 [==============================] - 276s 528ms/step - loss: 5.0347 - acc: 0.3674 - val_loss: 5.0911 - val_acc: 0.3674\n",
            "Epoch 6/10\n",
            "522/522 [==============================] - 275s 527ms/step - loss: 4.9374 - acc: 0.3740 - val_loss: 5.0301 - val_acc: 0.3717\n",
            "Epoch 7/10\n",
            "522/522 [==============================] - 274s 525ms/step - loss: 4.8608 - acc: 0.3793 - val_loss: 4.9963 - val_acc: 0.3741\n",
            "Epoch 8/10\n",
            "522/522 [==============================] - 275s 528ms/step - loss: 4.7956 - acc: 0.3842 - val_loss: 4.9609 - val_acc: 0.3772\n",
            "Epoch 9/10\n",
            "522/522 [==============================] - 275s 527ms/step - loss: 4.7401 - acc: 0.3890 - val_loss: 4.9431 - val_acc: 0.3784\n",
            "Epoch 10/10\n",
            "522/522 [==============================] - 275s 527ms/step - loss: 4.6830 - acc: 0.3933 - val_loss: 4.9204 - val_acc: 0.3802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faa26185e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z19hYjZ_4ls0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "a1eeab27-fd92-49e0-eb36-a9cce3e19347"
      },
      "source": [
        "NoneType = None\n",
        "type(NoneType)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwRTMvZm-eFA",
        "colab_type": "text"
      },
      "source": [
        "## Seq2Seq 번역기 작동시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q999LYp4Q5Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0du8Ko5fQ8xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더\n",
        "\n",
        "# 이전 시점의 상태를 보관할 텐서\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bo9vaplQ_cV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJjNXmBvUfnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 정수 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = eng_to_index['<sos>']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정한다.\n",
        "\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 단어로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_eng[sampled_token_index]\n",
        "\n",
        "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "        if (sampled_char == '<eos>' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxAcWaE3TZjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2ko(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            temp = temp + index_to_ko[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2eng(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=eng_to_index['<sos>']) and i!=eng_to_index['<eos>']):\n",
        "            temp = temp + index_to_eng[i] + ' '\n",
        "    return temp"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlNRpLCqTjLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "575e310e-18c1-480d-ec52-08bd444da6fc"
      },
      "source": [
        "for seq_index in [3,25,100,300,1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"원문 : \",seq2ko(encoder_input_train[seq_index]))\n",
        "  print(\"번역문 :\",seq2eng(decoder_input_train[seq_index]))\n",
        "  print(\"예측문 :\",decoded_sentence)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원문 :  넷째로는 주입식 교육 대신 학생들이 수업에 주도적으로 이끌어가는 ‘참여형 교육’을 위해 교과서 내용도 큰 폭으로 바뀌었다. \n",
            "번역문 : Fourthly, textbook contents have changed drastically for \"participatory education\", in which students take the initiative in class instead of learning by rote. \n",
            "예측문 :  Unlike the existing market, the world's largest number\n",
            "\n",
            "\n",
            "원문 :  푸른색 톤의 화면에 다채로운 색점들이 별처럼 빛나거나 종이 위에 푸른색의 선염이 번지는 김환기 스타일의 서정적 화면이다. \n",
            "번역문 : It's a lyrical screen of Kim Hwan-ki's style, with colorful colors shining like stars on a blue-toned screen or spreading blue-colored ombre on paper. \n",
            "예측문 :  The number of the world's largest number of the first\n",
            "\n",
            "\n",
            "원문 :  생태적 먹거리, 쉴거리, 볼거리를 찾겠다는 목표 아래 15년 계획의 친환경 수련원 조성 사업이 진행되고 있다. \n",
            "번역문 : Under the goal of finding ecological food, rest and sights, a 15-year program to create an eco-friendly training center is under way. \n",
            "예측문 :  According to the U.S. and the U.S. and the U.S. and\n",
            "\n",
            "\n",
            "원문 :  문재인 대통령과 이재용 삼성전자 부회장이 9일 저녁(한국 시각) 예정인 ‘인도 만남’을 놓고 여러 해석이 나온다. \n",
            "번역문 : President Moon Jae-in and Vice-Chairman Lee Jae-yong come up with various interpretations on \"India Meeting\" scheduled for the evening of the 9th (Korean time). \n",
            "예측문 :  The U.S. President Trump said that President Trump\n",
            "\n",
            "\n",
            "원문 :  그는그러면서 “국경지대를 통제가 불가하고 안전하지 못한 상태로 방치해 사람들이 몰래 들어오도록 둘 수는 없는 일”이라고 덧붙였다. \n",
            "번역문 : He added, \"We cannot leave the border area uncontrolled and unsafe, allowing people to sneak in.\" \n",
            "예측문 :  According to the U.S. and the U.S. and the U.S. is\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RELXPUB9hYhU",
        "colab_type": "text"
      },
      "source": [
        "## BLEU 사용(nltk 말고, 직접 구현으로)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exOXi9ZjIb77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from nltk.util import ngrams"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIvJ8RCA_cYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단순 카운트 함수\n",
        "def simple_count(tokens, n): # 토큰화 된 candidate 문장, n-gram에서의 n 이 두 가지를 인자로 받음.\n",
        "    return Counter(ngrams(tokens, n)) #문장에서 n-gram을 카운트"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXW1fae1_hDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_clip(candidate, reference_list, n):\n",
        "    cnt_ca = simple_count(candidate, n)\n",
        "    # Ca 문장에서 n-gram 카운트\n",
        "    \n",
        "    temp = dict()\n",
        "\n",
        "    for ref in reference_list: # 다수의 Ref 문장에 대해서 이하 반복\n",
        "        cnt_ref = simple_count(ref, n)\n",
        "        # Ref 문장에서 n-gram 카운트\n",
        "\n",
        "        for n_gram in cnt_ref: # 모든 Ref에 대해서 비교하여 특정 n-gram이 하나의 Ref에 가장 많이 등장한 횟수를 저장\n",
        "            if n_gram in temp:\n",
        "                temp[n_gram] = max(cnt_ref[n_gram], temp[n_gram]) # max_ref_count\n",
        "            else:\n",
        "                temp[n_gram] = cnt_ref[n_gram]\n",
        "\n",
        "    return {\n",
        "        n_gram: min(cnt_ca.get(n_gram, 0), temp.get(n_gram, 0)) for n_gram in cnt_ca\n",
        "        # count_clip=min(count, max_ref_count)\n",
        "        # 위의 get은 찾고자 하는 n-gram이 없으면 0을 반환한다.\n",
        "     }"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gaciw32AVFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modified_precision(candidate, reference_list, n):\n",
        "    clip = count_clip(candidate, reference_list, n) \n",
        "    total_clip = sum(clip.values()) # 분자\n",
        "\n",
        "    ct = simple_count(candidate, n)\n",
        "    total_ct = sum(ct.values()) #분모\n",
        "\n",
        "    if total_ct==0: # n-gram의 n이 커졌을 때 분모가 0이 되는 것을 방지\n",
        "      total_ct=1\n",
        "\n",
        "    return (total_clip / total_ct) # 보정된 정밀도\n",
        "    # count_clip의 합을 분자로 하고 단순 count의 합을 분모로 하면 보정된 정밀도"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYaeWSvGAbgW",
        "colab_type": "text"
      },
      "source": [
        "짧은 문장도 있기 때문에 감점을 주어야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFcP7bhCAbph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def closest_ref_length(candidate, reference_list): # Ca 길이와 가장 근접한 Ref의 길이를 리턴하는 함수\n",
        "    ca_len = len(candidate) # ca 길이\n",
        "    ref_lens = (len(ref) for ref in reference_list) # Ref들의 길이\n",
        "    closest_ref_len = min(ref_lens, key=lambda ref_len: (abs(ref_len - ca_len), ref_len))\n",
        "    # 길이 차이를 최소화하는 Ref를 찾아서 Ref의 길이를 리턴\n",
        "    return closest_ref_len"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycnxUI0oAjzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def brevity_penalty(candidate, reference_list):\n",
        "    ca_len = len(candidate)\n",
        "    ref_len = closest_ref_length(candidate, reference_list)\n",
        "\n",
        "    if ca_len > ref_len:\n",
        "        return 1\n",
        "    elif ca_len == 0 :\n",
        "    # candidate가 비어있다면 BP = 0 → BLEU = 0.0\n",
        "        return 0\n",
        "    else:\n",
        "        return np.exp(1 - ref_len/ca_len)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW1dd1xgAlm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bleu_score(candidate, reference_list, weights=[0.25, 0.25, 0.25, 0.25]):\n",
        "    bp = brevity_penalty(candidate, reference_list) # 브레버티 패널티, BP\n",
        "\n",
        "    p_n = [modified_precision(candidate, reference_list, n=n) for n, _ in enumerate(weights,start=1)] \n",
        "    #p1, p2, p3, ..., pn\n",
        "    score = np.sum([w_i * np.log(p_i) if p_i != 0 else 0 for w_i, p_i in zip(weights, p_n)])\n",
        "    return bp * np.exp(score)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcKPBCzfAncP",
        "colab_type": "text"
      },
      "source": [
        "## nltk를 이용한 BLEU(훨씬 편하고 모듈화)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTYtsa4GeBJN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "9648d9f2-15e8-4d73-c897-e5aef0a3eafa"
      },
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "candidate = 'In China, more than 10,000 students a year go into post-doctoral courses.'\n",
        "references = 'The government has been to be held in the first time'\n",
        "print(bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split()))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.537284965911771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IswHWwSeMSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "011d4266-9603-4eaa-9163-801db9f0ef28"
      },
      "source": [
        "candidate2 = 'President Moon Jae-in and Vice-Chairman Lee Jae-yong come up with various interpretations on \"India Meeting\" scheduled for the evening of the 9th (Korean time)'\n",
        "references2 = 'The U.S. President Trump said that President Trump'\n",
        "print(bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split()))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.537284965911771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5sY44G8e7pT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}