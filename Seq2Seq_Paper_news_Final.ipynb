{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_Paper_news_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1vzmLpeU80h9z0E17CDPnSO433OTRs62o",
      "authorship_tag": "ABX9TyOLg41zZL+EeF6Yh+xCw/uB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoo9519-AIdev/Learning/blob/master/Seq2Seq_Paper_news_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbhFyvhLxkQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import os\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import zipfile"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nslRFSGxsVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "46aba04c-118a-4e8f-8dac-d0c3d2dd43d5"
      },
      "source": [
        "text = pd.read_excel('/content/drive/My Drive/AI NLP 알고리즘 포트폴리오/Seq2Seq/3_문어체_뉴스(1)_200226.xlsx')\n",
        "text"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>날짜</th>\n",
              "      <th>자동분류1</th>\n",
              "      <th>자동분류2</th>\n",
              "      <th>자동분류3</th>\n",
              "      <th>URL</th>\n",
              "      <th>언론사</th>\n",
              "      <th>원문</th>\n",
              "      <th>번역문</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20961563</td>\n",
              "      <td>2018-10-01 00:00:00</td>\n",
              "      <td>경제,국제경제</td>\n",
              "      <td>IT_과학,IT_과학일반</td>\n",
              "      <td>문화,문화일반</td>\n",
              "      <td>http://www.sedaily.com/NewsView/1S5QRSR5T2</td>\n",
              "      <td>서울경제</td>\n",
              "      <td>스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.</td>\n",
              "      <td>Skinner's reward is mostly eye-watering.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20930897</td>\n",
              "      <td>2018-09-14 00:00:00</td>\n",
              "      <td>IT_과학,IT_과학일반</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www.sedaily.com/NewsView/1S4MSFM0IH</td>\n",
              "      <td>서울경제</td>\n",
              "      <td>심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.</td>\n",
              "      <td>Even some problems can be predicted.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20307875</td>\n",
              "      <td>2019-04-19 00:00:00</td>\n",
              "      <td>IT_과학,과학</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://news.kmib.co.kr/article/view.asp?arcid=...</td>\n",
              "      <td>국민일보</td>\n",
              "      <td>오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.</td>\n",
              "      <td>Only God will exactly know why.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20314977</td>\n",
              "      <td>2019-04-27 00:00:00</td>\n",
              "      <td>국제,중국</td>\n",
              "      <td>경제,국제경제</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://news.kmib.co.kr/article/view.asp?arcid=...</td>\n",
              "      <td>국민일보</td>\n",
              "      <td>중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.</td>\n",
              "      <td>Businesses should not overlook China's dispute.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20268904</td>\n",
              "      <td>2019-03-13 00:00:00</td>\n",
              "      <td>문화,방송_연예</td>\n",
              "      <td>사회,미디어</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://news.kmib.co.kr/article/view.asp?arcid=...</td>\n",
              "      <td>국민일보</td>\n",
              "      <td>박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.</td>\n",
              "      <td>Slow-beating songs often float over time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>2469942</td>\n",
              "      <td>20181022</td>\n",
              "      <td>사회,노동_복지</td>\n",
              "      <td>사회,사건_사고</td>\n",
              "      <td>사회,미디어</td>\n",
              "      <td>http://www.hani.co.kr/arti/opinion/because/866...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>당시에는 경찰의 금지통보로 청와대 근처 집회가 불가능하던 시절이라 과연 경찰이 막지...</td>\n",
              "      <td>At the time, it was a period when it was impos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>2462113</td>\n",
              "      <td>20181019</td>\n",
              "      <td>사회,사건_사고</td>\n",
              "      <td>정치,정치일반</td>\n",
              "      <td>사회,노동_복지</td>\n",
              "      <td>http://www.hani.co.kr/arti/society/society_gen...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>양승태 대법원과 박근혜 청와대의 대표적 재판거래 의혹 사건으로 꼽히는 전국교직원노동...</td>\n",
              "      <td>The testimony of a Blue House official at the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>2463985</td>\n",
              "      <td>20181019</td>\n",
              "      <td>경제,산업_기업</td>\n",
              "      <td>사회,사회일반</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www.hani.co.kr/arti/society/society_gen...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>윤석열 서울중앙지검장이 19일 국정감사에 출석해 ‘적폐수사 1호’로 꼽히는 한국항공...</td>\n",
              "      <td>Seoul Central District Prosecutor's Office Chi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200009</th>\n",
              "      <td>2463107</td>\n",
              "      <td>20181019</td>\n",
              "      <td>사회,사건_사고</td>\n",
              "      <td>국제,유럽_EU</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www.hani.co.kr/arti/society/society_gen...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>대법원에 재상고된 지 5년이 넘도록 재판이 지연되면서 양승태 대법원장 시절 대표적인...</td>\n",
              "      <td>The date of the ruling of the second appeal re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200010</th>\n",
              "      <td>2463530</td>\n",
              "      <td>20181019</td>\n",
              "      <td>사회,사건_사고</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www.hani.co.kr/arti/opinion/editorial/8...</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>‘양승태 대법원'은 민사소송규칙까지 고쳐 외교부가 대법원에 의견서를 제출할 수 있게...</td>\n",
              "      <td>It was also revealed through documents from th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200011 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID  ...                                                번역문\n",
              "0       20961563  ...           Skinner's reward is mostly eye-watering.\n",
              "1       20930897  ...               Even some problems can be predicted.\n",
              "2       20307875  ...                    Only God will exactly know why.\n",
              "3       20314977  ...    Businesses should not overlook China's dispute.\n",
              "4       20268904  ...          Slow-beating songs often float over time.\n",
              "...          ...  ...                                                ...\n",
              "200006   2469942  ...  At the time, it was a period when it was impos...\n",
              "200007   2462113  ...  The testimony of a Blue House official at the ...\n",
              "200008   2463985  ...  Seoul Central District Prosecutor's Office Chi...\n",
              "200009   2463107  ...  The date of the ruling of the second appeal re...\n",
              "200010   2463530  ...  It was also revealed through documents from th...\n",
              "\n",
              "[200011 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGGADAdix9XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text[:10000]\n",
        "text = text[['원문', '번역문']]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH1kjU21yPzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ko = text['원문']\n",
        "eng = text['번역문']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmU7EmWL0Gnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eng = eng.apply(lambda x : '<sos> '+ x + ' <eos>')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwIhtj2SzH7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faa35f44-a53a-4537-8a4d-ec6d0dde9ea9"
      },
      "source": [
        "eng[0] # eg = eng[i]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Skinner's reward is mostly eye-watering.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJxB0tnRy0Sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47f40d89-2dd2-4aec-9309-6d3724a413d8"
      },
      "source": [
        "ko[0] # k = ko[i]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hKal99eyWoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = [k.split() for k in ko] # 단어 단위로 encoder_input에 담는다.\n",
        "decoder_input = [['<sos>'] + eg.split() for eg in eng]\n",
        "decoder_target = [eg.split() + ['<eos>'] for eg in eng]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzDzAkBo26tf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "ec29250d-b0a6-4ebb-a333-4b9e0e118871"
      },
      "source": [
        "encoder_input[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['스키너가', '말한', '보상은', '대부분', '눈으로', '볼', '수', '있는', '현물이다.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFqq7nR_2VpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "4c18347a-89a7-4da1-9f3f-173bd4b3792f"
      },
      "source": [
        "decoder_input[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', \"Skinner's\", 'reward', 'is', 'mostly', 'eye-watering.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH8nfIUC4asY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "a83506ee-db68-4d5a-99b4-241193a8295f"
      },
      "source": [
        "decoder_target[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Skinner's\", 'reward', 'is', 'mostly', 'eye-watering.', '<eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3u_FJQ1EDaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pd_decoder_input = pd.DataFrame(decoder_input)\n",
        "# pd_decoder_input = pd_decoder_input.apply(lambda x: '<sos> ' + x)\n",
        "# pd_decoder_input"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-AIeZaLhfcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "8bdb47f9-4f2c-4e9f-e5e6-3ce7fba9f280"
      },
      "source": [
        "decoder_input[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<sos>', \"Skinner's\", 'reward', 'is', 'mostly', 'eye-watering.'],\n",
              " ['<sos>', 'Even', 'some', 'problems', 'can', 'be', 'predicted.'],\n",
              " ['<sos>', 'Only', 'God', 'will', 'exactly', 'know', 'why.'],\n",
              " ['<sos>', 'Businesses', 'should', 'not', 'overlook', \"China's\", 'dispute.'],\n",
              " ['<sos>', 'Slow-beating', 'songs', 'often', 'float', 'over', 'time.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNU8-HlChiId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "ea6d38dd-5366-4c3c-bc0c-cfb3b63efdde"
      },
      "source": [
        "decoder_target[:5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"Skinner's\", 'reward', 'is', 'mostly', 'eye-watering.', '<eos>'],\n",
              " ['Even', 'some', 'problems', 'can', 'be', 'predicted.', '<eos>'],\n",
              " ['Only', 'God', 'will', 'exactly', 'know', 'why.', '<eos>'],\n",
              " ['Businesses', 'should', 'not', 'overlook', \"China's\", 'dispute.', '<eos>'],\n",
              " ['Slow-beating', 'songs', 'often', 'float', 'over', 'time.', '<eos>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am671v841rST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 케라스 토크나이저를 통해 단어집합을 생성하고, 텍스트 시퀀스를 정수 시퀀스로 변환하는 정수 인코딩 과정을 거친다.\n",
        "\n",
        "tokenizer_ko = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_ko.fit_on_texts(encoder_input)\n",
        "encoder_input_ = tokenizer_ko.texts_to_sequences(encoder_input)\n",
        "\n",
        "tokenizer_eng = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_eng.fit_on_texts(decoder_input)\n",
        "decoder_input_ = tokenizer_eng.texts_to_sequences(decoder_input)\n",
        "decoder_target_ = tokenizer_eng.texts_to_sequences(decoder_target)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZXB6YVgiTJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_ = pad_sequences(encoder_input_, padding=\"post\")\n",
        "decoder_input_ = pad_sequences(decoder_input_, padding=\"post\")\n",
        "decoder_target_ = pad_sequences(decoder_target_, padding=\"post\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz3pYZJ-pPrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "06f590b3-d089-46d6-cf01-d1e94a4ff06e"
      },
      "source": [
        "decoder_target_ = pad_sequences(decoder_target_, padding='post')\n",
        "decoder_target_.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjVNSlxpilAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "7709cd9d-aabc-4d58-dd7c-bf125162f322"
      },
      "source": [
        "encoder_input_.shape, decoder_input_.shape, decoder_target_.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 25), (10000, 16), (10000, 15))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y5iYPLZixjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "d455dd26-29c4-4a9d-ac22-e48927364c81"
      },
      "source": [
        "ko_vocab_size = len(tokenizer_ko.word_index) + 1\n",
        "eng_vocab_size = len(tokenizer_eng.word_index) + 1\n",
        "print(\"한국어 단어 집합의 크기 : {:d}, 영어 단어 집합의 크기 : {:d}\".format(ko_vocab_size, eng_vocab_size))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "한국어 단어 집합의 크기 : 38652, 영어 단어 집합의 크기 : 22163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfOPF-bujFjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ko_to_index = tokenizer_ko.word_index\n",
        "index_to_ko = tokenizer_ko.index_word # 훈련 후 결과 비교할 때 사용\n",
        "\n",
        "eng_to_index = tokenizer_eng.word_index # 훈련 후 예측 과정에서 사용\n",
        "index_to_eng = tokenizer_eng.index_word # 훈련 후 결과 비교할 때 사용"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlfWYuFH0gxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_to_index_ = eng_to_index\n",
        "eng_to_index_['<eos>'] = 22163"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZCChQjUjQ7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "0523fe32-7743-4679-996b-214fe9795cd4"
      },
      "source": [
        "indices = np.arange(encoder_input_.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2068 9418 9413 ... 7607 2050 2307]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uVDua6gjU-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_ = encoder_input_[indices]\n",
        "decoder_input_ = decoder_input_[indices]\n",
        "decoder_target_ = decoder_target_[indices]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb_xVSH-japC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "c6645718-6d91-4df1-c7fa-1598853c1dfa"
      },
      "source": [
        "# 훈련 데이터 분리\n",
        "\n",
        "n_of_val = int(33000*0.1)\n",
        "print(n_of_val)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pSxCapxjgIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_train = encoder_input_[:-n_of_val]\n",
        "decoder_input_train = decoder_input_[:-n_of_val]\n",
        "decoder_target_train = decoder_target_[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input_[-n_of_val:]\n",
        "decoder_input_test = decoder_input_[-n_of_val:]\n",
        "decoder_target_test = decoder_target_[-n_of_val:]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c3x7M7YjlRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "cdafd1b8-a2f9-4f3d-b22e-844d38dacbad"
      },
      "source": [
        "print(encoder_input_train.shape)\n",
        "print(decoder_input_train.shape)\n",
        "print(decoder_target_train.shape)\n",
        "print(encoder_input_test.shape)\n",
        "print(decoder_input_test.shape)\n",
        "print(decoder_target_test.shape)\n",
        "\n",
        "# 차원 25, 16, 16로 조정"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6700, 25)\n",
            "(6700, 16)\n",
            "(6700, 15)\n",
            "(3300, 25)\n",
            "(3300, 16)\n",
            "(3300, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6s2ewm0rXVO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "de8a4f79-c6ce-486f-df7c-5d972bd06752"
      },
      "source": [
        "a_zero = np.zeros((6700, 1))\n",
        "b_zero = np.zeros((3300, 1))\n",
        "\n",
        "decoder_target_train = np.append(decoder_target_train, a_zero, axis=1)\n",
        "decoder_target_test = np.append(decoder_target_test, b_zero, axis=1)\n",
        "\n",
        "print(encoder_input_train.shape)\n",
        "print(decoder_input_train.shape)\n",
        "print(decoder_target_train.shape)\n",
        "print(encoder_input_test.shape)\n",
        "print(decoder_input_test.shape)\n",
        "print(decoder_target_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6700, 25)\n",
            "(6700, 16)\n",
            "(6700, 16)\n",
            "(3300, 25)\n",
            "(3300, 16)\n",
            "(3300, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7RTNGVVsJrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a_zero = np.zeros((6700, 1))\n",
        "# b_zero = np.zeros((3300, 1))\n",
        "\n",
        "# np.append(decoder_target_train, a_zero, axis=1)\n",
        "# np.append(decoder_target_test, b_zero, axis=1)\n",
        "\n",
        "# print(decoder_target_train.shape)\n",
        "# print(decoder_target_test.shape)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxKhIQwvpZFP",
        "colab_type": "text"
      },
      "source": [
        "numpy 배열 확인 및 조정(연습)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNdnq_Fak_Nb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "9b3ff4c3-362c-4429-8822-ff088328f1ac"
      },
      "source": [
        "decoder_input_test"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    1,     9,   270, ...,  3098,     0,     0],\n",
              "       [    1,    22,   147, ...,     0,     0,     0],\n",
              "       [    1,    23,   110, ..., 15572,     0,     0],\n",
              "       ...,\n",
              "       [    1,   590, 18871, ...,   399,   586,     0],\n",
              "       [    1,   381,   789, ...,     0,     0,     0],\n",
              "       [    1,     9,   495, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G45lqL5dnt7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "a660deac-e299-4ae6-ad22-a6e71874e9c9"
      },
      "source": [
        "testnp = np.arange(1, 21)\n",
        "testnp"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFoMov06n8IU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "cd6deee7-c3da-4024-921c-e91c2a7e673a"
      },
      "source": [
        "testnp2 = testnp.reshape(5, 4)\n",
        "testnp2.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLLjgElmpBL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "c97eb4d8-c0c5-4bbd-e2c6-fe36d7c73a46"
      },
      "source": [
        "testnp2.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW1AchyBoMYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "0369d17c-d365-4c66-a844-8ae68595d0a9"
      },
      "source": [
        "a = np.zeros((5, 1))\n",
        "np.append(testnp2, a, axis=1)\n",
        "\n",
        "# 이런식으로 decoder_target_test / train을 수동으로 zeros패딩 시켜주자."
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  2.,  3.,  4.,  0.],\n",
              "       [ 5.,  6.,  7.,  8.,  0.],\n",
              "       [ 9., 10., 11., 12.,  0.],\n",
              "       [13., 14., 15., 16.,  0.],\n",
              "       [17., 18., 19., 20.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhdLOknRjn4G",
        "colab_type": "text"
      },
      "source": [
        "## Seq2Seq 기계 번역기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRLkreDJjs1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Y-RwAdjyGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 50"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9kiTI-fjzyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더\n",
        "\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(ko_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhmBI_zokAcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더\n",
        "\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(eng_vocab_size, latent_dim) # 임베딩 층\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "\n",
        "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "decoder_dense = Dense(eng_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyubdfWQkMFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYrU-Sy_kO-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxEoP8UJkTK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "b4bfeba8-3e35-40fb-dd51-16f6f30fdd7c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 50)     1932600     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 50)     1108150     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking (Masking)               (None, None, 50)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "masking_1 (Masking)             (None, None, 50)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50), (None,  20200       masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       masking_1[0][0]                  \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 22163)  1130313     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,211,463\n",
            "Trainable params: 4,211,463\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d36-vEqnkU18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3afa473a-b52e-485c-871d-4eb0583c6b5f"
      },
      "source": [
        "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test), batch_size = 128, epochs = 50)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "53/53 [==============================] - 9s 175ms/step - loss: 8.3686 - acc: 0.0620 - val_loss: 7.2106 - val_acc: 0.2268\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 6.7498 - acc: 0.2233 - val_loss: 6.6253 - val_acc: 0.2268\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 6.3497 - acc: 0.2233 - val_loss: 6.4418 - val_acc: 0.2268\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 6.1283 - acc: 0.2233 - val_loss: 6.3369 - val_acc: 0.2273\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.9821 - acc: 0.2379 - val_loss: 6.2844 - val_acc: 0.2534\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.8755 - acc: 0.2575 - val_loss: 6.2370 - val_acc: 0.2631\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.7905 - acc: 0.2630 - val_loss: 6.2161 - val_acc: 0.2655\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.7192 - acc: 0.2674 - val_loss: 6.1920 - val_acc: 0.2687\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.6554 - acc: 0.2739 - val_loss: 6.1757 - val_acc: 0.2737\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.5987 - acc: 0.2789 - val_loss: 6.1633 - val_acc: 0.2754\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.5461 - acc: 0.2811 - val_loss: 6.1489 - val_acc: 0.2766\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.4969 - acc: 0.2838 - val_loss: 6.1373 - val_acc: 0.2772\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.4522 - acc: 0.2864 - val_loss: 6.1223 - val_acc: 0.2789\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.4096 - acc: 0.2883 - val_loss: 6.1177 - val_acc: 0.2792\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.3697 - acc: 0.2903 - val_loss: 6.1115 - val_acc: 0.2784\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 7s 129ms/step - loss: 5.3319 - acc: 0.2915 - val_loss: 6.1060 - val_acc: 0.2800\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 7s 129ms/step - loss: 5.2943 - acc: 0.2931 - val_loss: 6.1087 - val_acc: 0.2786\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 7s 129ms/step - loss: 5.2583 - acc: 0.2949 - val_loss: 6.0900 - val_acc: 0.2819\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 7s 133ms/step - loss: 5.2233 - acc: 0.2962 - val_loss: 6.0817 - val_acc: 0.2806\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 7s 132ms/step - loss: 5.1887 - acc: 0.2977 - val_loss: 6.0880 - val_acc: 0.2821\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.1538 - acc: 0.2995 - val_loss: 6.0919 - val_acc: 0.2807\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.1207 - acc: 0.3008 - val_loss: 6.1070 - val_acc: 0.2788\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.0884 - acc: 0.3021 - val_loss: 6.0930 - val_acc: 0.2811\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.0584 - acc: 0.3035 - val_loss: 6.1061 - val_acc: 0.2840\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 5.0279 - acc: 0.3047 - val_loss: 6.1044 - val_acc: 0.2815\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.9983 - acc: 0.3059 - val_loss: 6.1382 - val_acc: 0.2802\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.9674 - acc: 0.3078 - val_loss: 6.1336 - val_acc: 0.2801\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.9379 - acc: 0.3099 - val_loss: 6.1379 - val_acc: 0.2791\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.9075 - acc: 0.3111 - val_loss: 6.1542 - val_acc: 0.2801\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.8774 - acc: 0.3135 - val_loss: 6.1390 - val_acc: 0.2824\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.8487 - acc: 0.3160 - val_loss: 6.1505 - val_acc: 0.2794\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.8184 - acc: 0.3179 - val_loss: 6.1460 - val_acc: 0.2834\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.7888 - acc: 0.3197 - val_loss: 6.1971 - val_acc: 0.2819\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 7s 132ms/step - loss: 4.7589 - acc: 0.3215 - val_loss: 6.1614 - val_acc: 0.2833\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.7273 - acc: 0.3238 - val_loss: 6.1762 - val_acc: 0.2788\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.6959 - acc: 0.3255 - val_loss: 6.1848 - val_acc: 0.2820\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.6666 - acc: 0.3271 - val_loss: 6.1992 - val_acc: 0.2795\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.6363 - acc: 0.3297 - val_loss: 6.2056 - val_acc: 0.2797\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.6072 - acc: 0.3310 - val_loss: 6.2020 - val_acc: 0.2814\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.5795 - acc: 0.3331 - val_loss: 6.1990 - val_acc: 0.2781\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.5515 - acc: 0.3347 - val_loss: 6.2251 - val_acc: 0.2798\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 7s 129ms/step - loss: 4.5245 - acc: 0.3364 - val_loss: 6.2265 - val_acc: 0.2773\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.4976 - acc: 0.3387 - val_loss: 6.2314 - val_acc: 0.2752\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 7s 129ms/step - loss: 4.4724 - acc: 0.3399 - val_loss: 6.2412 - val_acc: 0.2766\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.4465 - acc: 0.3418 - val_loss: 6.2794 - val_acc: 0.2786\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.4221 - acc: 0.3438 - val_loss: 6.2707 - val_acc: 0.2743\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 7s 130ms/step - loss: 4.3973 - acc: 0.3450 - val_loss: 6.2877 - val_acc: 0.2759\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 7s 129ms/step - loss: 4.3728 - acc: 0.3470 - val_loss: 6.2930 - val_acc: 0.2740\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 7s 129ms/step - loss: 4.3499 - acc: 0.3484 - val_loss: 6.3432 - val_acc: 0.2783\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 7s 129ms/step - loss: 4.3264 - acc: 0.3498 - val_loss: 6.3162 - val_acc: 0.2755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8fc9ed2a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z19hYjZ_4ls0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "5eb0aa20-fd7f-4ebd-c401-9b63f9c4d5ef"
      },
      "source": [
        "NoneType = None\n",
        "type(NoneType)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCZGIRnN4gMN",
        "colab_type": "text"
      },
      "source": [
        "'''\n",
        "list의 변수명을 list로 한건지 확인해보자\n",
        "아니면 if is 함수 통해서 알아보자\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t3oF4Vx4u4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if encoder_input_train is None:\n",
        "    pass\n",
        "\n",
        "if decoder_input_train is None:\n",
        "    pass\n",
        "\n",
        "# Nonetype문제 해결"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwRTMvZm-eFA",
        "colab_type": "text"
      },
      "source": [
        "## Seq2Seq 번역기 작동시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q999LYp4Q5Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0du8Ko5fQ8xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더\n",
        "\n",
        "# 이전 시점의 상태를 보관할 텐서\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bo9vaplQ_cV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJjNXmBvUfnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 정수 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = eng_to_index['<sos>']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정한다.\n",
        "\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 단어로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_eng[sampled_token_index]\n",
        "\n",
        "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "        if (sampled_char == '<eos>' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxAcWaE3TZjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2ko(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            temp = temp + index_to_ko[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2eng(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=eng_to_index['<sos>']) and i!=eng_to_index['<eos>']):\n",
        "            temp = temp + index_to_eng[i] + ' '\n",
        "    return temp"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlNRpLCqTjLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "c15d159d-d28f-4808-c502-f833b9729ea0"
      },
      "source": [
        "for seq_index in [3,50,100,300,1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"원문 : \",seq2ko(encoder_input_train[seq_index]))\n",
        "  print(\"번역문 :\",seq2eng(decoder_input_train[seq_index]))\n",
        "  print(\"예측문 :\",decoded_sentence)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원문 :  발병원인이 아직 밝혀져 있지 않아 근본적인 치료법은 없는 상태다. \n",
            "번역문 : The cause of the disease is not known yet, so there is no fundamental treatment. \n",
            "예측문 :  The market is to be used that have but it is not not\n",
            "\n",
            "\n",
            "원문 :  시위에는 10대 초반의 어린 학생들까지 참여하는 등 수천명이 모였다. \n",
            "번역문 : Thousands gathered in the demonstration, including even young students in their early teens. \n",
            "예측문 :  The photo has been been found for the world with his\n",
            "\n",
            "\n",
            "원문 :  발견 당시 김씨는 건강에 지장이 없는 상태였던 것으로 전해졌다. \n",
            "번역문 : Kim was reportedly not in danger of life when he was discovered. \n",
            "예측문 :  The government is not been used to make as the same\n",
            "\n",
            "\n",
            "원문 :  아직 정식 개봉 전이라 서툰 소개가 걱정이 되기도 한다. \n",
            "번역문 : The introduction may be awkward, with it not yet released, is also worrisome. \n",
            "예측문 :  The government has been been been been enough for not\n",
            "\n",
            "\n",
            "원문 :  삶의 목표가 분명한 것이 이렇게 좋은 것인지 미처 몰랐습니다. \n",
            "번역문 : I never realized that the obvious goal of life was so good like this. \n",
            "예측문 :  The government is not the lot of I can be to be but\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "272tFzoRxM4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    }
  ]
}